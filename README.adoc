// = Kokkidio Readme
// :author: Lennart Steffen
// :email: Lennart.Steffen@wahyd.tu-berlin.de
:source-highlighter: highlight.js
:toc:
:toc-placement!:

:Eigen: https://eigen.tuxfamily.org/[Eigen]
:Kokkos: https://kokkos.org/[Kokkos]
:GPLv3: https://www.gnu.org/licenses/gpl-3.0.en.html[GPLv3]
:wahyd: https://www.wahyd.tu-berlin.de/
:maplink: https://eigen.tuxfamily.org/dox/classEigen_1_1Map.html

:viewmap: link:./include/Kokkidio/ViewMap.hpp[ViewMap]
:dualviewmap: link:./include/Kokkidio/DualViewMap.hpp[DualViewMap]
:parallelrange: link:./include/Kokkidio/ParallelRange.hpp[ParallelRange]


image::./media/Kokkidio_Logo.svg[]

_Kokkidio_ is a header-only template library 
designed to provide interoperability between the linear algebra library {Eigen} 
and the performance portability framework {Kokkos}. 
Its aim is to allow the easy-to-read, succinct source code of {Eigen} 
to be compiled to fast machine code on all the platforms supported by {Kokkos}.  

toc::[]


== Overview

_Kokkidio_ consists of three interlocking elements:

* An iteration range class (`ParallelRange`), 
which allows threads to efficiently access their assigned elements, 
* parallel dispatch functions (`parallel_for` and `parallel_reduce`) 
compatible with functors taking `ParallelRange`, and
* the <<_data_structures, data structures>> `ViewMap` and `DualViewMap`, 
which combine an `Eigen::Map` and a `Kokkos::View`.

It allows you to write code like this (see link:./src/examples/axpy.cpp[file]):

.ViewMap construction, copying data, and SAXPY with Kokkidio
[%collapsible,id=kokkidio_ex]
====
[,cpp]
----
using namespace Kokkidio;
float a {0.5};
int size {10};

using FloatArray = DualViewMap<Eigen::ArrayXf>;
/* You may have an existing Eigen object */
Eigen::ArrayXf x_existing {size};
/* No need to replace it. You can simply wrap it in a (Dual)ViewMap: */
FloatArray x {x_existing};

/* Or you can construct them from sizes */
FloatArray y {size}, z {size};

/* We can use Kokkos functions on (Dual)ViewMaps, because their members
 * "MapView::view", and
 * "DualViewMap::view_<target>()" 
 * return a Kokkos::View */
Kokkos::deep_copy( y.view_host(), 123 );

/* Likewise, we can use Eigen functions on (Dual)ViewMaps, as their members
 * "MapView::map", and
 * "DualViewMap::map_<target>()"
 * return an Eigen::Map.
 * Outside of a parallel dispatch, only the host side is accessible. */
x.map_host().setRandom();
y.map_host().setRandom();

/* Copying data between host and compute target is simple: */
x.copyToTarget(); // if the compute target is the host, this does nothing
y.copyToTarget();

/* This is how a parallel computation on the target is performed: */
parallel_for( size, KOKKOS_LAMBDA(ParallelRange<> rng){
	rng(z) = a * rng(x) + rng(y);
});
/* After the computation, you may copy the results back to the host */
z.copyToHost();
----
====

== Why Kokkos?

{Kokkos} is a portability and parallelism framework, 
which allows users to write code that compiles and runs 
on a wide range of hardware, especially both CPUs and GPUs.
It provides data structures
(https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html[`Kokkos::View`]),
as well as functions for 
https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html[parallel dispatch],
and
// It 
may be viewed as a common abstraction 
for various programming models and backends, e.g.
OpenMP, including target offloading, OpenACC, CUDA, HIP, and SYCL.
Here's an example:

.SAXPY with Kokkos
[%collapsible,id=kokkos_ex]
====
[,cpp]
----
float a {0.5};
std::size_t dim1 {10};
/* for more details, see
 * https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html#constructing-a-view
 */
using View = Kokkos::View<float*, Kokkos::DefaultExecutionSpace>;
View x {dim1}, y {dim1}, z {dim1};
/* fill arrays in some way,
 * e.g. using deep_copy or within a parallel dispatch ... */

/* and now do the computation in parallel */
Kokkos::parallel_for( dim1, KOKKOS_LAMBDA(std::size_t i){
	z(i) = a * x(i) + y(i);
});
----
====

While modern compilers already allow targeting multiple CPU architectures,
due to ISAs functioning as a reliable standard (x86(-64), ARM, ...),
GPU architectures and programming models are much less intercompatible.
If you wrote your code using CUDA, 
but want to run it on an Intel PonteVecchio GPU, 
you will have to rewrite large parts of it.

Using {Kokkos} for new projects allows you to avoid that type of effort.
For existing projects, it allows a step-by-step migration, 
because backend-specific code will still compile 
when using Kokkos on top of that backend.

// GPU architectures don't just vary between vendors, 
// but often also between product generations and product lines of a single vendor.
// // e.g. GCN being superseded by RDNA and CDNA, 
// // or <NVIDIA>


// Therefore, expressing a programming task 
// through Kokkos' data structures and parallel dispatch functions
// allows it to be run on basically any hardware

== Why Eigen?

{Eigen} is a linear algebra library, 
which allows writing any such operations in a readable, succinct manner,
while compiling to highly optimised machine code.
Instead of implementing matrix, vector, or coefficient-wise operations 
using loops, the 'Eigen way' is to operate on whole data structures 
using their overloaded operators or member functions. Here's an example:

// .Dot product in pure C++
// [%collapsible,id=eigen_ex]
// ====
// [,cpp]
// ----
// std::size_t size {10};
// std::vector<double> a {size}, b {size};
// /* fill vectors in some way ... */
// /* then loop over them and track the sum */
// double sum {0};
// for (std::size_t i=0; i<size; ++i){
// 	sum += a * b;
// }
// ----
// ====

// .Dot product in Eigen
// [%collapsible]
// ====
// [,cpp]
// ----
// Eigen::Index size {10};
// Eigen::VectorXd a {size}, b {size};
// /* fill vectors in some way ... */
// double sum = a.dot(b);
// ----
// ====


.SAXPY in pure C++
[%collapsible,id=eigen_ex]
====
[,cpp]
----
std::size_t size {10};
double a {0.5};
std::vector<double> x {size}, y {size}, z {size};
/* fill vectors in some way ... */
/* then loop over them and perform the computation element-wise */
for (std::size_t i=0; i<size; ++i){
	z[i] = a * x[i] + y[i];
}
----
====

.SAXPY in Eigen
[%collapsible]
====
[,cpp]
----
Eigen::Index size {10};
double a {0.5};
Eigen::VectorXd x {size}, y {size}, z {size};
/* fill vectors in some way, e.g. using member func setRandom() ... */
/* The computation is expressed with the whole object: */
z = a * x + y;
----
====

In addition to the benefits of letting a well-tested library handle common operations,
Eigen also performs extensive optimisations on the underlying loops.
This notably includes explicit vectorisation for all common CPU vector extensions, 
such as the SSE and AVX families on x86, ARM NEON, and others.
// mention expression templates?

// Since version 3.4, Eigen functions can be called from CUDA/HIP kernels,
// and its compatibility with SYCL is in a usable state since at least early 2024
// and under active development.
// However, neither its allocators for dynamically-sized data structures, 
// nor SIMD parallelism (like vectorisation on CPUs) 
// are currently available on GPUs.
// It does provide the {maplink}[`Eigen::Map`]
// class, though, 
// with which other data structures can be treated like an Eigen object,
// if they expose a data pointer and their memory layout and stride(s) are known.

== And why Kokkidio?

There exist a number of problems when trying to use Eigen's functionality on GPUs,
which are detailed below -- and which _Kokkidio_ aims to address.

=== The problems

. *Data structures* +
Since version 3.4, Eigen functions can be called from CUDA/HIP kernels,
and its compatibility with SYCL is in a usable state since at least early 2024
and under active development.
However, only fixed-size objects can be created on GPUs -- 
dynamically-sized data structures are only available on and from the host.
There is the {maplink}[`Eigen::Map`] class, though, 
with which other data structures can be treated like an Eigen object,
if they expose a data pointer and their memory layout and stride(s) are known.

. *Loop abstraction and parallelism 1* +
In the <<kokkos_ex,Kokkos example>> above, you can see 
the functor passed to Kokkos' `parallel_for` 
(the `KOKKOS_LAMBDA` in that case) 
containing the instructions for an *individual loop iteration*.
By contrast, the *loop is fully abstracted* in the <<eigen_ex,Eigen example>>.
There is no _user-facing_ loop iteration variable in an Eigen operation 
that could be used to parallelise operations.
+
Of course, that loop still exists, deep within the Eigen library.
While it could potentially be parallelised there, 
// sweeping changes to Eigen's interface would be necessary as well 
// to make this practical.
the interface of Eigen is not set up to facilitate anything like this.
Therefore, sweeping changes to the whole library would be necessary, 
with all the compatibility and testing issues that brings.
// Parallel execution would have to be conditional, 
// as a kernel dispatch would not make sense for every operation,
// and to prevent accidental nesting.

. *Parallelism 2: Chunk sizes, vectorisation, and readability* +
// Furthermore, when 
When
parallelising an Eigen operation as a library user,
the ideal strategy for assigning work to threads 
is rather different between CPUs and GPUs.
On a GPU, the large number of relatively weak cores 
leads to many small units of work performing better.
// a large number of small units of work perform better, 
// while 
By contrast, 
on a CPU, fewer, larger, and contiguous chunks are preferable,
to allow for vectorised operations. 
+
// Let's use a (slightly) more involved example, 
// where an individual thread's operation is still done with Eigen:
// Here's an example with Eigen, where columns of matrices are (dot-) multiplied:
Here's an example to illustrate this difference.
We're not using SAXPY, but instead multiply matrix columns, 
so that individual threads still use Eigen functionality.
+
.Multiply matrix columns (see link:./src/examples/dot.cpp[file])
[%collapsible]
====
[,cpp]
----
int nRows {4}, nCols {1000};
Eigen::MatrixXd a {nRows, nCols}, b;
b.resizeLike(a);
/* fill matrices in some way ... */
double result; // let's sum up the results to not need another array
/* One could do a nested loop and manually implement the dot product.
 * We skip that here, because for that you wouldn't use Eigen */

/* Instead, one could either distribute individual column-multiplications, 
 * as one might do on a GPU, if nCols >> nRows */
result = 0;
for (int i=0; i<nCols; ++i){
	result += a.col(i).transpose() * b.col(i);
	/* this is equivalent: */
	// result += a.col(i).dot( b.col(i) );
}

/* Or, one could distribute blocks of the matrices to threads and let Eigen
 * handle the loop over columns, as may be preferable on a CPU.
 * This can be a lot faster, as it allows Eigen to vectorise the operation. */
result = 0;
int nCores {4}; // just for illustration
int nColsPerCore {nCols / nCores}; // not handling remainders

for (int i=0; i<nCores; ++i){
	int firstCol {i * nColsPerCore};
	result += (
		a.middleCols(firstCol, nColsPerCore).transpose() * 
		b.middleCols(firstCol, nColsPerCore)
	).trace(); // trace = sum of the diagonal
}
----
====
Not only do the loop bodies differ quite significantly,
but Eigen's advantage of short and readable source code 
is also somewhat diminished, when parallelising code in this fashion.


=== Approaching solutions

_Kokkidio_ solves the first issue of Eigen's data structures 
not being compatible with GPU programming models by 
wrapping a `Kokkos::View` in a class called `ViewMap`.
It provides access to the contained `Kokkos::View`, 
but additionally uses Eigen's {maplink}[`Map`] feature 
to allow the contained data to be treated like an `Eigen` object --
even on GPUs. More detail is provided in the section <<_data_structures>>.

As long as Eigen's functionality  abstraction is still useful

== Parallel dispatch and the `ParallelRange` class

Using Kokkos' 
https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html[parallel dispatch]
is similar to a `for`-loop,
in the sense that users provide a range and an iteration variable. 
Here's an example:

.Kokkos parallel dispatch
[%collapsible]
====
[,cpp]
----
std::size_t size {10} // that's our range
Kokkos::parallel_for( size, KOKKOS_LAMBDA(int i){ // i is our iteration variable
	// each value for i now goes to a single thread
} );
----
====



== Data structures

=== `ViewMap`

The core of the `ViewMap` class (see link:./include/Kokkidio/ViewMap.hpp[file])
are the two member functions `map()` and `view()`,
which return an `Eigen::Map`, and a `Kokkos::View` respectively, 
and thus allow it to be used in either library's functions.

`ViewMap` takes two template parameters:

. `EigenType`: The `Eigen` class to be used as the map type, 
e.g. `Eigen::MatrixXd` or `Eigen::Array3i`. 
The return type of `map()` behaves the same way as this type. 
Only dense types are currently supported. 
. A `Target` enumeration value, which can be either `host` or `device`. 
This parameter is optional. 
Its default value matches `Kokkos::DefaultExecutionSpace`.

`ViewMap` can be instantiated either using an existing `Eigen` object, 
or using the same size parameters as you would for the `Eigen` type. 
Here's what happens when you create a `ViewMap`:

. With an existing `Eigen` object: 

.. Instantiation on `Target::host`:
No allocation is performed. 
An unmanaged `Kokkos::View` is created, 
using the existing object's data pointer and sizes.

.. Instantiation on `Target::device`:
the `Eigen` object's sizes are used to create a matching managed `Kokkos::View` 
on the device.

. With size parameters: 
A managed `Kokkos::View` is created using these sizes on `Target`.
The same size parameters are allowed as for the respective `Eigen` type.
This means, creating vector types (1D) requires only a single size parameter,
and fixed size types can be created without them.

In all of the above cases, the data pointers of `view()` and `map()` 
contain the same address. 
Furthermore, when instantiating a `ViewMap` with 
a non-const, owning `Eigen` object (i.e. not itself an `Eigen::Map`),
a non-owning pointer to the object is stored 
to allow resizing both the `Kokkos::View` and the `Eigen` object 
via `ViewMap::resize()`.

==== Examples

The examples below are taken from
link:./src/examples/ViewMap.cpp[examples/ViewMap.cpp].

.Expand ViewMap examples
[%collapsible]
====
[,cpp]
----
using namespace Kokkidio;
int nRows {10}, nCols {20};

/* existing Eigen object */
Eigen::ArrayXXd eigenArray {nRows, nCols};

/* Create ViewMap using a constructor or factory function.
 * Deduces Eigen type, and uses default target */
ViewMap mv1 {eigenArray};
auto mv2 = viewMap(eigenArray);

/* Create ViewMap using factory function for specific target,
 * while deducing Eigen type */
auto mv3 = viewMap<Target::host>(eigenArray);

/* Create ViewMap using size parameters. 
 * ArrayXXd is dynamically sized in both dimensions, 
 * so two parameters are required */
ViewMap<Eigen::ArrayXXd> mv4 {nRows, nCols};

/* ArrayXd is a column vector, so only rows are required */
ViewMap<Eigen::ArrayXd> mv5 {nRows};

/* Array3d is a fixed size type, so no parameters are required */
ViewMap<Eigen::Array3d> mv6;

/* set values on host, using Eigen's assignment operator on ViewMap::map() */
mv1.map() = 1;

/* set values on target, using Kokkos::deep_copy with ViewMap::view() */
Kokkos::deep_copy(mv2.view(), 2);

/* set values on target with parallel dispatch: */
/* with Kokkidio::ParallelRange */
parallel_for( mv3.cols(), KOKKOS_LAMBDA(ParallelRange<> rng){
	rng(mv3) = 3;
});

/* or just an integer, using the standard Kokkos-style */
parallel_for( mv4.size(), KOKKOS_LAMBDA(int i){
	mv4.data()[i] = 4;
});
----
====

==== Synopsis

.Expand synopsis of ViewMap
[%collapsible]
====
[,cpp]
----

template<typename _EigenType, Target targetArg = DefaultTarget>
class ViewMap {
public:
	static constexpr Target target { ExecutionTarget<targetArg> };
	using EigenType_host = _EigenType;
	/* EigenType_host and EigenType_target may differ in const-ness */
	using EigenType_target = std::conditional_t<target == Target::host,
		EigenType_host,
		std::remove_const_t<EigenType_host>
	>;

	using ThisType = ViewMap<EigenType_target, target>;

	using Scalar     = typename EigenType_target::Scalar;
	using MapType    = Eigen::Map<EigenType_host>;
	/* only types with a continuous memory layout are currently supported */
	static_assert( is_contiguous<EigenType_target>() );

	/* Translations of "target" into Kokkos spaces */
	using MemorySpace    = Kokkidio::MemorySpace   <target>;
	using ExecutionSpace = Kokkidio::ExecutionSpace<target>;
	/* The Kokkos::View data type is either fully dynamic or fully fixed-size,
	 * i.e. Scalar** or Scalar[nRows][nCols],
	 * and always uses LayoutLeft */
	using ViewType   = Kokkos::View<..., Kokkos::LayoutLeft, MemorySpace>;
	using HostMirror = typename ViewType::HostMirror;

public:

	/* constructors */
	ViewMap(); // default, allocation only for fixed size types
	ViewMap(Index size); // 1D types
	ViewMap(Index rows, Index cols); // 2D types
	ViewMap( _EigenType& hostObj ); // existing Eigen objects

	/* "resize" and constructors can only be called from host */
	void resize(Index rows, Index cols);

	/* get some info about type and status */
	KOKKOS_FUNCTION constexpr bool isManaged() const;
	KOKKOS_FUNCTION bool isAlloc() const;

	/* data pointer */
	KOKKOS_FUNCTION Scalar* data();
	KOKKOS_FUNCTION const Scalar* data() const;

	/* get Eigen::Map */
	KOKKOS_FUNCTION MapType map() const;

	/* and Kokkos::View */
	KOKKOS_FUNCTION ViewType view() const;

	/* sizes */
	KOKKOS_FUNCTION Index rows() const;
	KOKKOS_FUNCTION Index cols() const;
	KOKKOS_FUNCTION Index size() const;
};

/* detection */
template<typename T>
inline constexpr bool is_ViewMap_v = ...;


/* factory functions */

/* specify target, deduce EigenType */
template<Target target = DefaultTarget, typename EigenType>
ViewMap<EigenType, target> viewMap( EigenType& eigenObj );

/* specify EigenType, optionally specify target, fixed size */
template<typename EigenType, Target target = DefaultTarget>
ViewMap<EigenType, target> viewMap();

/* specify EigenType, optionally specify target, 1D */
template<typename EigenType, Target target = DefaultTarget>
ViewMap<EigenType, target> viewMap(Index vectorSize);

/* specify EigenType, optionally specify target, 2D */
template<typename EigenType, Target target = DefaultTarget>
ViewMap<EigenType, target> viewMap(Index rows, Index cols);
----
====

=== `DualViewMap`

`DualViewMap` (see link:./include/Kokkidio/DualViewMap.hpp[file])
is designed to facilitate easy data exchange between `host` 
and the compute `Target`. 
To this end, it provides the member functions
`copyToTarget()` 
and 
`copyToHost()`.


It takes the same template parameters as <<_viewmap,`ViewMap`>>, 
i.e. an `Eigen` type, and a `Target` value.
While a `ViewMap` only exists on _either_ `host` or `device`, 
`DualViewMap` always consists of _two_ ``ViewMap``s, 
of which one is located on `host`, 
and the other on the specified `Target`. 
If the `Target` is also `host`, then the two views are identical,
and `copyTo...()` operations are correspondingly skipped.

To access the ``ViewMap``s, it provides the member functions
`get_host()`
and
`get_target()`,
as well as shortcuts to their ``map()``/``view()`` member functions 
in the form of
``map_host()``/``map_target()`` and ``view_host()``/``view_target()``.

Similar to <<_viewmap,`ViewMap`>>, it also allows to `resize()` its data,
and does so on both `host` and the specified `Target`.

==== Examples

The examples below are taken from
link:./src/examples/DualViewMap.cpp[examples/DualViewMap.cpp].

.Expand DualViewMap examples
[%collapsible]
====
[,cpp]
----
using namespace Kokkidio;
int nRows {10}, nCols {20};

/* existing Eigen object */
Eigen::ArrayXXd eigenArray {nRows, nCols};
/* By default, when initialising with an Eigen object,
 * the object's data is copied to the target. 
 * This behaviour be changed with an optional parameter: DontCopyToTarget */
DualViewMap d1 {eigenArray};
auto d2 = dualViewMap(eigenArray, DontCopyToTarget);
/* Otherwise, a DualViewMap can be created in exactly the same ways as a 
 * ViewMap, so please refer to ViewMap.cpp for more examples. */

/* with DualViewMap, you can set your values on host, 
 * then copy them to the target: */
d2.map_host() = 123;
d2.copyToTarget();

auto print = [&](std::string_view descriptor){
	std::cout
		<< "d2, values on host, " << descriptor << ":\n"
		<< d2.map_host() << '\n';
};
print("before");

/* Now you can do some computations on the target, 
 * then copy the values back */
parallel_for(d2.cols(), KOKKOS_LAMBDA(ParallelRange<> rng){
	rng(d2) += 1;
});
d2.copyToHost();

print("after");
----
====

==== Synopsis

.Expand synopsis of DualViewMap
[%collapsible]
====
[,cpp]
----

template<typename _EigenType, Target targetArg = DefaultTarget>
class DualViewMap {
public:
	static constexpr Target target { ExecutionTarget<targetArg> };
	using EigenType_host = _EigenType;

	using ThisType = DualViewMap<EigenType_host, target>;
	using ViewMap_host   = ViewMap<EigenType_host, Target::host>;
	using ViewMap_target = ViewMap<EigenType_host, target>;
	using EigenType_target = typename ViewMap_target::EigenType_target;
	using Scalar = typename ViewMap_target::Scalar;

	using ViewType_host   = typename ViewMap_host  ::ViewType;
	using ViewType_target = typename ViewMap_target::ViewType;
	using ExecutionSpace_target = typename ViewMap_target::ExecutionSpace;

	using MapType_host   = typename ViewMap_host  ::MapType;
	using MapType_target = typename ViewMap_target::MapType;

public:

	/* constructors */
	DualViewMap(); // default, allocation only for fixed size types
	DualViewMap(Index size); // 1D types
	DualViewMap(Index rows, Index cols); // 2D types
	DualViewMap(
		EigenType_host& hostObj,
		DualViewCopyOnInit copyToTarget = CopyToTarget
	);  // existing Eigen objects


	/* "assign", "resize" and constructors can only be called from host */
	void assign( EigenType_host& hostObj );
	void resize(Index rows, Index cols);

	/* get some info about type and status */
	KOKKOS_FUNCTION bool isAlloc_host() const;
	KOKKOS_FUNCTION bool isAlloc_target() const;

	/* get ViewMaps */
	KOKKOS_FUNCTION ViewMap_host   get_host  () const;
	KOKKOS_FUNCTION ViewMap_target get_target() const;

	template<Target _target>
	KOKKOS_FUNCTION auto get() const
		-> std::conditional<_target == target, ViewMap_target, ViewMap_host>;

	/* get Kokkos::Views */
	KOKKOS_FUNCTION ViewType_host   view_host  () const;
	KOKKOS_FUNCTION ViewType_target view_target() const;

	template<Target _target>
	KOKKOS_FUNCTION auto view() const
		-> std::conditional<_target == target, ViewType_target, ViewType_host>;

	/* shortcut to view_target */
	KOKKOS_FUNCTION ViewType_target view() const;

	/* get Eigen::Maps */
	KOKKOS_FUNCTION MapType_host   map_host  () const;
	KOKKOS_FUNCTION MapType_target map_target() const;

	template<Target _target>
	KOKKOS_FUNCTION auto map() const
		-> std::conditional<_target == target, MapType_target, MapType_host>;

	/* shortcut to map_target */
	KOKKOS_FUNCTION MapType_target map() const;

	/* sizes */
	KOKKOS_FUNCTION Index rows() const;
	KOKKOS_FUNCTION Index cols() const;
	KOKKOS_FUNCTION Index size() const;

	/* copy */
	void copyToTarget(bool async = false);
	void copyToHost(bool async = false);
};

/* detection */
template<typename T>
inline constexpr bool is_DualViewMap_v = ...;


/* factory functions */

/* specify target, deduce EigenType */
template<Target target = DefaultTarget, typename EigenType>
DualViewMap<EigenType, target> dualViewMap(
	EigenType& eigenObj,
	DualViewCopyOnInit copyToTarget = CopyToTarget
);

/* specify EigenType, optionally specify target, fixed size */
template<typename EigenType, Target target = DefaultTarget>
DualViewMap<EigenType, target> dualViewMap();

/* specify EigenType, optionally specify target, 1D */
template<typename EigenType, Target target = DefaultTarget>
DualViewMap<EigenType, target> dualViewMap(Index vectorSize);

/* specify EigenType, optionally specify target, 2D */
template<typename EigenType, Target target = DefaultTarget>
DualViewMap<EigenType, target> dualViewMap(Index rows, Index cols);
----
====

== Licence

_Kokkidio_ is maintained by the
Chair of Water Resources Management and Modelling of Hydrosystems of the
Technische Universität Berlin,
or *wahyd* for short ({wahyd}[Link]).
It is distributed under a {gplv3} (link:./LICENCE[Licence text]).
Licence types for the libraries used in _Kokkidio_
are listed in the link:./LICENCE.README[LICENCE.README] file.

== Name and Logo

The name _Kokkidio_ is based on the assumptions that 

. {Kokkos} refers to the Greek *Κόκκος* (engl.: *grain*, though possibly a play on *kernel*), and that 
. {Eigen} refers to eigenvalues and eigenvectors.

The latter are _ιδιοτιμή_ (idiotimí) and _ιδιοδιάνυσμα_ (idiodiánysma) in Greek, 
from which the prefix _ιδιο_ (idio) was taken
(engl.: _same_, though it could also be from _ίδιος_ = own, or self, 
which is the meaning of _eigen_ in German). 
_κοκκίδιο_ (kokkídio) could be seen as a https://en.wikipedia.org/wiki/Portmanteau[portmanteau] of _Kokkos_ and _idio_, 
but is in fact the Greek word for _granule_, so not far off _Kokkos_ itself.

The logo is a stretched/sheared map of a recolouration of the https://kokkos.org/img/kokkos-logo.png[Kokkos logo], 
with the eigenvectors of that mapping drawn as arrows.


